Testing...
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CatsVSDogs:
quantization: BINARY || bit width: 1
 
Training Loss for epoch 0: 2.876905575942993
Training Loss for epoch 1: 2.32150467300415
Test performance:    correct: 2477  total: 5000   accuracy: 0.495400
######################################################################################
 
Testing net torchvision_alexnet_noBN with following parameters on Dataset CatsVSDogs:
quantization: BINARY || bit width: 1
 
Training Loss for epoch 0: 1.6237424571990966
Training Loss for epoch 1: 1.3409237065315247
Test performance:    correct: 2641  total: 5000   accuracy: 0.528200
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CatsVSDogs:
quantization: BINARY || bit width: 1
 
Training Loss for epoch 0: 0.8914514894008636
Training Loss for epoch 1: 0.7602451156139374
Test performance:    correct: 2489  total: 5000   accuracy: 0.497800
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CatsVSDogs:
quantization: BINARY || bit width: 1
 
Training Loss for epoch 0: 1.7060589647293092
Training Loss for epoch 1: 1.359750858783722
Test performance:    correct: 2497  total: 5000   accuracy: 0.499400
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 2
 
Training Loss for epoch 0: 0.6931788355827332
Training Loss for epoch 1: 0.6932179793357849
Test performance:    correct: 2491  total: 5000   accuracy: 0.498200
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 2
 
Training Loss for epoch 0: 0.6931802091598511
Training Loss for epoch 1: 0.6932624116897583
Test performance:    correct: 2500  total: 5000   accuracy: 0.500000
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 2
 
Training Loss for epoch 0: 0.7002554889678955
Training Loss for epoch 1: 0.6940904016494751
Test performance:    correct: 2555  total: 5000   accuracy: 0.511000
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 2
 
Training Loss for epoch 0: 0.6990114876747131
Training Loss for epoch 1: 0.6932559106826782
Test performance:    correct: 2500  total: 5000   accuracy: 0.500000
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 3
 
Training Loss for epoch 0: 0.6898685696601867
Training Loss for epoch 1: 0.6260711558818817
Test performance:    correct: 2979  total: 5000   accuracy: 0.595800
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 3
 
Training Loss for epoch 0: 0.6932220147132874
Training Loss for epoch 1: 0.693158299446106
Test performance:    correct: 2500  total: 5000   accuracy: 0.500000
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 3
 
Training Loss for epoch 0: 0.6572889134407044
Training Loss for epoch 1: 0.482398225235939
Test performance:    correct: 2521  total: 5000   accuracy: 0.504200
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 3
 
Training Loss for epoch 0: 0.726111747932434
Training Loss for epoch 1: 0.6977720234870911
Test performance:    correct: 2500  total: 5000   accuracy: 0.500000
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 4
 
Training Loss for epoch 0: 0.6546008183002472
Training Loss for epoch 1: 0.5186206172466278
Test performance:    correct: 3605  total: 5000   accuracy: 0.721000
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 4
 
Training Loss for epoch 0: 0.6931098630905151
Training Loss for epoch 1: 0.6925007501602173
Test performance:    correct: 2500  total: 5000   accuracy: 0.500000
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 4
 
Training Loss for epoch 0: 0.6320148247241973
Training Loss for epoch 1: 0.49031674580574036
Test performance:    correct: 2507  total: 5000   accuracy: 0.501400
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 4
 
Training Loss for epoch 0: 0.7292494769096375
Training Loss for epoch 1: 0.688889693069458
Test performance:    correct: 2608  total: 5000   accuracy: 0.521600
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 5
 
Training Loss for epoch 0: 0.6429948353767395
Training Loss for epoch 1: 0.5008952716827393
Test performance:    correct: 3551  total: 5000   accuracy: 0.710200
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 5
 
Training Loss for epoch 0: 0.6928466389656067
Training Loss for epoch 1: 0.6896229741096497
Test performance:    correct: 2779  total: 5000   accuracy: 0.555800
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 5
 
Training Loss for epoch 0: 0.648877590084076
Training Loss for epoch 1: 0.5035306502819061
Test performance:    correct: 2475  total: 5000   accuracy: 0.495000
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 5
 
Training Loss for epoch 0: 0.7628216581344605
Training Loss for epoch 1: 0.6578703439235687
Test performance:    correct: 2516  total: 5000   accuracy: 0.503200
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 6
 
Training Loss for epoch 0: 0.6401781953811646
Training Loss for epoch 1: 0.49852080998420717
Test performance:    correct: 3468  total: 5000   accuracy: 0.693600
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 6
 
Training Loss for epoch 0: 0.6929503910064697
Training Loss for epoch 1: 0.6911827955245972
Test performance:    correct: 2892  total: 5000   accuracy: 0.578400
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 6
 
Training Loss for epoch 0: 0.6412460741996765
Training Loss for epoch 1: 0.4806028125524521
Test performance:    correct: 2477  total: 5000   accuracy: 0.495400
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 6
 
Training Loss for epoch 0: 0.7891041707515717
Training Loss for epoch 1: 0.6745519607543945
Test performance:    correct: 2507  total: 5000   accuracy: 0.501400
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 7
 
Training Loss for epoch 0: 0.6449002532482148
Training Loss for epoch 1: 0.5113834943294525
Test performance:    correct: 3481  total: 5000   accuracy: 0.696200
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 7
 
Training Loss for epoch 0: 0.6929381155014038
Training Loss for epoch 1: 0.6906605651855469
Test performance:    correct: 2686  total: 5000   accuracy: 0.537200
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 7
 
Training Loss for epoch 0: 0.6527326309680939
Training Loss for epoch 1: 0.49106707365512847
Test performance:    correct: 2484  total: 5000   accuracy: 0.496800
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 7
 
Training Loss for epoch 0: 0.7795322176456452
Training Loss for epoch 1: 0.6722452466964721
Test performance:    correct: 2520  total: 5000   accuracy: 0.504000
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 8
 
Training Loss for epoch 0: 0.64247261428833
Training Loss for epoch 1: 0.5075031735897064
Test performance:    correct: 3523  total: 5000   accuracy: 0.704600
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 8
 
Training Loss for epoch 0: 0.6926009696960449
Training Loss for epoch 1: 0.6893639446258545
Test performance:    correct: 2978  total: 5000   accuracy: 0.595600
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 8
 
Training Loss for epoch 0: 0.6394838822364807
Training Loss for epoch 1: 0.48066119737625124
Test performance:    correct: 2455  total: 5000   accuracy: 0.491000
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CatsVSDogs:
quantization: INT || bit width: 8
 
Training Loss for epoch 0: 0.7646013501167297
Training Loss for epoch 1: 0.6543142974853515
Test performance:    correct: 2499  total: 5000   accuracy: 0.499800
Files already downloaded and verified
Files already downloaded and verified
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CIFAR10:
quantization: BINARY || bit width: 1
 
Training Loss for epoch 0: 26.152539040985108
Training Loss for epoch 1: 38.83837596710205
Test performance:    correct: 989  total: 10000   accuracy: 0.098900
######################################################################################
 
Testing net torchvision_alexnet_noBN with following parameters on Dataset CIFAR10:
quantization: BINARY || bit width: 1
 
Training Loss for epoch 0: 9.216040761108399
Training Loss for epoch 1: 8.143574823455811
Test performance:    correct: 1403  total: 10000   accuracy: 0.140300
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CIFAR10:
quantization: BINARY || bit width: 1
 
Training Loss for epoch 0: 2.6994031423950196
Training Loss for epoch 1: 2.161033812637329
Test performance:    correct: 3536  total: 10000   accuracy: 0.353600
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CIFAR10:
quantization: BINARY || bit width: 1
 
Training Loss for epoch 0: 9.126841972503662
Training Loss for epoch 1: 4.832240941314697
Test performance:    correct: 985  total: 10000   accuracy: 0.098500
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 2
 
Training Loss for epoch 0: 2.3026920973205565
Training Loss for epoch 1: 2.3027038916015625
Test performance:    correct: 1000  total: 10000   accuracy: 0.100000
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 2
 
Training Loss for epoch 0: 2.302730821838379
Training Loss for epoch 1: 2.3027317179107665
Test performance:    correct: 1000  total: 10000   accuracy: 0.100000
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 2
 
Training Loss for epoch 0: 2.287730661087036
Training Loss for epoch 1: 2.269681426925659
Test performance:    correct: 1188  total: 10000   accuracy: 0.118800
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 2
 
Training Loss for epoch 0: 2.3044290293884275
Training Loss for epoch 1: 2.3028606492614747
Test performance:    correct: 953  total: 10000   accuracy: 0.095300
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 3
 
Training Loss for epoch 0: 1.9798457189178467
Training Loss for epoch 1: 1.3318348766708374
Test performance:    correct: 5917  total: 10000   accuracy: 0.591700
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 3
 
Training Loss for epoch 0: 2.3025587530517577
Training Loss for epoch 1: 2.301572699737549
Test performance:    correct: 1733  total: 10000   accuracy: 0.173300
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 3
 
Training Loss for epoch 0: 1.434589755859375
Training Loss for epoch 1: 1.0425170059585571
Test performance:    correct: 6710  total: 10000   accuracy: 0.671000
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 3
 
Training Loss for epoch 0: 2.3017346887207033
Training Loss for epoch 1: 2.3016974295806887
Test performance:    correct: 1073  total: 10000   accuracy: 0.107300
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 4
 
Training Loss for epoch 0: 1.7020950831985473
Training Loss for epoch 1: 1.1712051500320435
Test performance:    correct: 6174  total: 10000   accuracy: 0.617400
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 4
 
Training Loss for epoch 0: 2.2858311190795897
Training Loss for epoch 1: 1.8488348752212524
Test performance:    correct: 4228  total: 10000   accuracy: 0.422800
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 4
 
Training Loss for epoch 0: 1.402590920791626
Training Loss for epoch 1: 1.0040303909683228
Test performance:    correct: 6732  total: 10000   accuracy: 0.673200
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 4
 
Training Loss for epoch 0: 1.5911773156356812
Training Loss for epoch 1: 1.0822875473213196
Test performance:    correct: 6537  total: 10000   accuracy: 0.653700
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 5
 
Training Loss for epoch 0: 1.67206842628479
Training Loss for epoch 1: 1.169865926399231
Test performance:    correct: 6347  total: 10000   accuracy: 0.634700
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 5
 
Training Loss for epoch 0: 2.2122026784133912
Training Loss for epoch 1: 1.6546370513153077
Test performance:    correct: 4164  total: 10000   accuracy: 0.416400
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 5
 
Training Loss for epoch 0: 1.4076106774139405
Training Loss for epoch 1: 0.99155062707901
Test performance:    correct: 6827  total: 10000   accuracy: 0.682700
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 5
 
Training Loss for epoch 0: 1.5929751889038086
Training Loss for epoch 1: 1.1950412747955321
Test performance:    correct: 6403  total: 10000   accuracy: 0.640300
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 6
 
Training Loss for epoch 0: 1.6552244593811034
Training Loss for epoch 1: 1.1614895519828796
Test performance:    correct: 6045  total: 10000   accuracy: 0.604500
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 6
 
Training Loss for epoch 0: 2.165015977096558
Training Loss for epoch 1: 1.6125884549713134
Test performance:    correct: 4641  total: 10000   accuracy: 0.464100
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 6
 
Training Loss for epoch 0: 1.3863561101913453
Training Loss for epoch 1: 0.9926619360733032
Test performance:    correct: 6726  total: 10000   accuracy: 0.672600
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 6
 
Training Loss for epoch 0: 1.5876179187202453
Training Loss for epoch 1: 1.2023464225196838
Test performance:    correct: 6288  total: 10000   accuracy: 0.628800
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 7
 
Training Loss for epoch 0: 1.6628700366592408
Training Loss for epoch 1: 1.169522253818512
Test performance:    correct: 6382  total: 10000   accuracy: 0.638200
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 7
 
Training Loss for epoch 0: 2.160054815940857
Training Loss for epoch 1: 1.6448150592422486
Test performance:    correct: 4616  total: 10000   accuracy: 0.461600
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 7
 
Training Loss for epoch 0: 1.40369774394989
Training Loss for epoch 1: 0.9936176763153076
Test performance:    correct: 6813  total: 10000   accuracy: 0.681300
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 7
 
Training Loss for epoch 0: 1.574205220375061
Training Loss for epoch 1: 1.1555280372428893
Test performance:    correct: 6393  total: 10000   accuracy: 0.639300
######################################################################################
 
Testing net self_alexnet with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 8
 
Training Loss for epoch 0: 1.657222024116516
Training Loss for epoch 1: 1.1532561786270141
Test performance:    correct: 6469  total: 10000   accuracy: 0.646900
######################################################################################
 
Testing net torchvision_alexnet_tanh_noBN with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 8
 
Training Loss for epoch 0: 2.1901377000808715
Training Loss for epoch 1: 1.652096132583618
Test performance:    correct: 4588  total: 10000   accuracy: 0.458800
######################################################################################
 
Testing net torchvision_alexnet_BN_PreA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 8
 
Training Loss for epoch 0: 1.3945847546386718
Training Loss for epoch 1: 0.9925856605529785
Test performance:    correct: 6690  total: 10000   accuracy: 0.669000
######################################################################################
 
Testing net torchvision_alexnet_BN_PostA with following parameters on Dataset CIFAR10:
quantization: INT || bit width: 8
 
Training Loss for epoch 0: 1.5561436168289184
Training Loss for epoch 1: 1.1425667145729066
Test performance:    correct: 6523  total: 10000   accuracy: 0.652300
